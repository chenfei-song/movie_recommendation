{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T14:24:09.446825Z",
     "start_time": "2020-12-17T14:24:04.562473Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# basic packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "from scipy import sparse\n",
    "import pickle as pkl\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# self-build modules\n",
    "import sys\n",
    "sys.path.append('../model')\n",
    "from mf_nn import *\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. data loading and sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T04:18:36.223350Z",
     "start_time": "2020-12-17T04:18:26.320563Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../ml-latest/ratings.csv')\n",
    "df_tag = pd.read_csv('../ml-latest/genome-scores.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T04:18:41.983333Z",
     "start_time": "2020-12-17T04:18:36.254130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of users: 20000\n",
      "number of items: 1000\n",
      "number of ratings: 1179969\n"
     ]
    }
   ],
   "source": [
    "# sampled df\n",
    "df_sample = sample_df(df, user_thresh=20, item_thresh=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T04:18:42.731596Z",
     "start_time": "2020-12-17T04:18:42.019877Z"
    }
   },
   "outputs": [],
   "source": [
    "# tag of sampled movies\n",
    "sample_tag = df_tag[df_tag['movieId'].isin(df_sample.movieId.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T04:19:33.729224Z",
     "start_time": "2020-12-17T04:18:42.767454Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "952005\n",
      "227964\n",
      "(1000, 20000)\n",
      "(1000, 20000)\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = train_test_split_by_time(df_sample)\n",
    "print(len(train_df))\n",
    "print(len(test_df))\n",
    "\n",
    "rating_train = train_df.pivot(index='movieId', columns='userId', values='rating')\n",
    "rating_test = test_df.pivot(index='movieId', columns='userId', values='rating')\n",
    "print(rating_train.shape)\n",
    "print(rating_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T04:20:25.502740Z",
     "start_time": "2020-12-17T04:19:35.346190Z"
    }
   },
   "outputs": [],
   "source": [
    "# split train_df into training set and validation set by timestamp\n",
    "cf_nn_train_df, cf_nn_val_df = train_test_split_by_time(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T04:20:29.931542Z",
     "start_time": "2020-12-17T04:20:29.928115Z"
    }
   },
   "outputs": [],
   "source": [
    "# parameters to be tuned\n",
    "maxIter_list = [5, 15, 25]\n",
    "regParam_list = [0.1, 0.01]\n",
    "k_list = [20, 30, 50]\n",
    "rank_list = [10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = list(itertools.product(maxIter_list, regParam_list, k_list, rank_list))\n",
    "val_y = cf_nn_val_df.iloc[:, -2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 hybrid model without movie tag embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to load finised epochs from local file\n",
    "try:\n",
    "    with open('./mse_mae_list.pkl', 'rb') as f:\n",
    "        mse_list, mae_list, break_point = pkl.load(f)\n",
    "        \n",
    "# initialize local pkl file if not existing\n",
    "except:\n",
    "    mse_list, mae_list, break_point = [], [], 0\n",
    "    with open('./mse_mae_list.pkl', 'wb') as f:\n",
    "        pkl.dump([mse_list, mae_list, break_point], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter tuning without tag embedded\n",
    "for idx, (max_iter, regparam, k, rank) in enumerate(params):\n",
    "    if idx < break_point:\n",
    "        continue\n",
    "    try:\n",
    "        print(f'params:{max_iter},{regparam},{k},{rank}')\n",
    "        model_cfnn = mf_nn(max_iter = max_iter, regparam = regparam, k = k, rank = rank, movie_tag_embed = False) \n",
    "        model_cfnn.fit(cf_nn_train_df, sample_tag)\n",
    "        val_x = np.array(list(cf_nn_val_df.copy().drop('timestamp', axis = 1).apply(lambda x: model_cfnn.uf_dict[x['userId']] + model_cfnn.if_dict[x['movieId']] + model_cfnn.tag_dict[x['movieId']], axis=1).values))\n",
    "        mse, mae = model_cfnn.nn.evaluate(val_x, val_y, verbose = 0)\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "    except:\n",
    "        print(f'Broke at index: {idx}, params: {max_iter}, {regparam}, {k}, {rank}')\n",
    "        break\n",
    "        \n",
    "with open('./mse_mae_list.pkl', 'wb') as f:\n",
    "    pkl.dump([mse_list, mae_list, idx], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 0.1, 30, 10)\n"
     ]
    }
   ],
   "source": [
    "# best parameter\n",
    "with open('./mse_mae_list.pkl', 'rb') as f:\n",
    "    print(params[np.argmin(pkl.load(f)[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 hybrid model with movie tag embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-16T15:28:56.116207Z",
     "start_time": "2020-12-16T15:28:56.111592Z"
    }
   },
   "outputs": [],
   "source": [
    "# try to load finised epochs from local file\n",
    "try:\n",
    "    with open('./mse_mae_list_tag_embed.pkl', 'rb') as f:\n",
    "        mse_list, mae_list, break_point = pkl.load(f)\n",
    "        \n",
    "# initialize local pkl file if not existing\n",
    "except:\n",
    "    mse_list, mae_list, break_point = [], [], 0\n",
    "    with open('./mse_mae_list_tag_embed.pkl', 'wb') as f:\n",
    "        pkl.dump([mse_list, mae_list, break_point], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T07:11:07.343577Z",
     "start_time": "2020-12-17T04:20:36.845884Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params:20,0.1,20,10\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.1,20,15\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.1,20,20\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.1,30,10\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.1,30,15\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.1,30,20\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.1,50,10\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.1,50,15\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.1,50,20\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.01,20,10\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.01,20,15\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.01,20,20\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.01,30,10\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.01,30,15\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.01,30,20\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.01,50,10\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.01,50,15\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n",
      "params:20,0.01,50,20\n",
      "Training begins.......\n",
      "training set created\n",
      "start training neural network......\n",
      "model training finished\n"
     ]
    }
   ],
   "source": [
    "# parameter tuning with tag embedded\n",
    "for idx, (max_iter, regparam, k, rank) in enumerate(params):\n",
    "    if idx < break_point:\n",
    "        continue\n",
    "    try:\n",
    "        print(f'params:{max_iter},{regparam},{k},{rank}')\n",
    "        model_cfnn = mf_nn(max_iter = max_iter, regparam = regparam, k = k, rank = rank, movie_tag_embed = True) \n",
    "        model_cfnn.fit(cf_nn_train_df, sample_tag)\n",
    "        val_x = np.array(list(cf_nn_val_df.copy().drop('timestamp', axis = 1).apply(lambda x: model_cfnn.uf_dict[x['userId']] + model_cfnn.if_dict[x['movieId']] + model_cfnn.tag_dict[x['movieId']], axis=1).values))\n",
    "        mse, mae = model_cfnn.nn.evaluate(val_x, val_y, verbose = 0)\n",
    "        mse_list.append(mse)\n",
    "        mae_list.append(mae)\n",
    "    except:\n",
    "        print(f'Broke at index: {idx}, params: {max_iter}, {regparam}, {k}, {rank}')\n",
    "        break\n",
    "with open('./mse_mae_list_tag_embed.pkl', 'wb') as f:\n",
    "    pkl.dump([mse_list, mae_list, idx], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-17T07:29:29.499990Z",
     "start_time": "2020-12-17T07:29:29.489087Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15, 0.1, 30, 10)\n"
     ]
    }
   ],
   "source": [
    "# best parameter\n",
    "with open('./mse_mae_list_tag_embed.pkl', 'rb') as f:\n",
    "    print(params[np.argmin(pkl.load(f)[1])])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
